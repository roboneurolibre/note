{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_output",
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "build = 'archive' # 'archive' uses the neurolibre archive of the data., 'latest' would download the latest versions of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<head>\n",
    "\n",
    "<link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n",
    "<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=STIX+Two+Text:ital,wght@0,400;0,700;1,400&display=swap\" rel=\"stylesheet\">\n",
    "</head>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<center>\n",
    "<b>\n",
    "<h3>\n",
    "A PDF is not enough: Crowdsourcing the T<sub>1</sub> mapping common ground via the ISMRM reproducibility challenge\n",
    "</h3>\n",
    "\n",
    "<p>\n",
    "<sup>*</sup>Mathieu Boudreau<sup>1,2</sup>, <sup>*</sup>Agah Karakuzu<sup>1</sup>, Julien Cohen-Adad<sup>1,3,4,5</sup>, Ecem Bozkurt<sup>6</sup>, Madeline Carr<sup>7,8</sup>, Marco Castellaro<sup>9</sup>, Luis Concha<sup>10</sup>, Mariya Doneva<sup>11</sup>, Seraina Dual<sup>12</sup>, Alex Ensworth<sup>13,14</sup>, Alexandru Foias<sup>1</sup>, Véronique Fortier<sup>15,16</sup>, Refaat E. Gabr<sup>17</sup>, Guillaume Gilbert<sup>18</sup>, Carri K. Glide-Hurst<sup>19</sup>, Matthew Grech-Sollars<sup>20,21</sup>, Siyuan Hu<sup>22</sup>, Oscar Jalnefjord<sup>23,24</sup>, Jorge Jovicich<sup>25</sup>, Kübra Keskin<sup>6</sup>, Peter Koken<sup>11</sup>, Anastasia Kolokotronis<sup>13,26</sup>, Simran Kukran<sup>27,28</sup>, Nam. G. Lee<sup>6</sup>, Ives R. Levesque<sup>13,29</sup>, Bochao Li<sup>6</sup>, Dan Ma<sup>22</sup>, Burkhard Mädler<sup>30</sup>, Nyasha Maforo<sup>31,32</sup>, Jamie Near<sup>33,34</sup>, Erick Pasaye<sup>10</sup>, Alonso Ramirez-Manzanares<sup>35</sup>, Ben Statton<sup>36</sup>,Christian Stehning<sup>30</sup>, Stefano Tambalo<sup>25</sup>, Ye Tian<sup>6</sup>, Chenyang Wang<sup>37</sup>, Kilian Weiss<sup>30</sup>, Niloufar Zakariaei<sup>38<sup>, Shuo Zhang<sup>30</sup>, Ziwei Zhao<sup>6</sup>, Nikola Stikov<sup>1,2,39</sup>\n",
    "</p>\n",
    "</b>\n",
    "\n",
    "<ul style=\"list-style-type: none\">\n",
    "<li><sup>*</sup>Authors MB and AK contributed equally to this work</li>\n",
    "</ul>\n",
    "</center>\n",
    "\n",
    "<p style=\"text-align:justify;font-size:70%\">\n",
    "<sup>1</sup>NeuroPoly Lab, Polytechnique Montréal, Montreal, Quebec, Canada,\n",
    "<sup>2</sup>Montreal Heart Institute, Montreal, Quebec, Canada,\n",
    "<sup>3</sup>Unité de Neuroimagerie Fonctionnelle (UNF), Centre de recherche de l’Institut Universitaire de Gériatrie de Montréal (CRIUGM), Montreal, Quebec, Canada,\n",
    "<sup>4</sup>Mila - Quebec AI Institute, Montreal, QC, Canada,\n",
    "<sup>5</sup>Centre de recherche du CHU Sainte-Justine, Université de Montréal, Montreal, QC, Canada,\n",
    "<sup>6</sup>Magnetic Resonance Engineering Laboratory (MREL), University of Southern California, Los Angeles, California, USA,\n",
    "<sup>7</sup>Medical Physics, Ingham Institute for Applied Medical Research, Liverpool, Australia,\n",
    "<sup>8</sup>Department of Medical Physics, Liverpool and Macarthur Cancer Therapy Centres, Liverpool, Australia,\n",
    "<sup>9</sup>Department of Information Engineering, University of Padova, Padova, Italy,\n",
    "<sup>10</sup>Institute of Neurobiology, Universidad Nacional Autónoma de México Campus Juriquilla, Querétaro, México,\n",
    "<sup>11</sup>Philips Research Hamburg, Germany,\n",
    "<sup>12</sup>Stanford University, Stanford, California, United States,\n",
    "<sup>13</sup>Medical Physics Unit, McGill University, Montreal, Canada,\n",
    "<sup>14</sup>University of British Columbia, Vancouver, Canada,\n",
    "<sup>15</sup>Department of Medical Imaging, McGill University Health Centre, Montreal, Quebec, Canada\n",
    "<sup>16</sup>Department of Radiology, McGill University, Montreal, Quebec, Canada,\n",
    "<sup>17</sup>Department of Diagnostic and Interventional Imaging, University of Texas Health Science Center at Houston, McGovern Medical School, Houston, Texas, USA, \n",
    "<sup>18</sup>MR Clinical Science, Philips Canada, Mississauga, Ontario, Canada,\n",
    "<sup>19</sup>Department of Human Oncology, University of Wisconsin-Madison, Madison, Wisconsin, USA,\n",
    "<sup>20</sup>Centre for Medical Image Computing, Department of Computer Science, University College London, London, UK,\n",
    "<sup>21</sup>Lysholm Department of Neuroradiology, National Hospital for Neurology and Neurosurgery, University College London Hospitals NHS Foundation Trust, London, UK,\n",
    "<sup>22</sup>Department of Biomedical Engineering, Case Western Reserve University, Cleveland, Ohio, USA, \n",
    "<sup>23</sup>Department of Medical Radiation Sciences, Institute of Clinical Sciences, Sahlgrenska Academy, University of Gothenburg, Gothenburg, Sweden,\n",
    "<sup>24</sup>Biomedical Engineering, Sahlgrenska University Hospital, Gothenburg, Sweden, \n",
    "<sup>25</sup>Center for Mind/Brain Sciences, University of Trento, Italy,\n",
    "<sup>26</sup>Hopital Maisonneuve-Rosemont, Montreal, Canada,\n",
    "<sup>27</sup>Bioengineering, Imperial College London, UK,\n",
    "<sup>28</sup>Radiotherapy and Imaging, Insitute of Cancer Research, Imperial College London, UK,\n",
    "<sup>29</sup>Research Institute of the McGill University Health Centre, Montreal, Canada,\n",
    "<sup>30</sup>Clinical Science, Philips Healthcare, Germany,\n",
    "<sup>31</sup>Department of Radiological Sciences, University of California Los Angeles, Los Angeles, CA, USA,\n",
    "<sup>32</sup>Physics and Biology in Medicine IDP, University of California Los Angeles, Los Angeles, CA, USA,\n",
    "<sup>33</sup>Douglas Brain Imaging Centre, Montreal, Canada,\n",
    "<sup>34</sup>Sunnybrook Research Institute, Toronto, Canada,\n",
    "<sup>35</sup>Computer Science Department, Centro de Investigación en Matemáticas, A.C., Guanajuato, México,\n",
    "<sup>36</sup>Medical Research Council, London Institute of Medical Sciences, Imperial College London, London, United Kingdom,\n",
    "<sup>37</sup>Department of Radiation Oncology - CNS Service, The University of Texas MD Anderson Cancer Center, Texas, USA,\n",
    "<sup>38</sup>Department of Biomedical Engineering, University of British Columbia, British Columbia, Canada,\n",
    "<sup>39</sup>Center for Advanced Interdisciplinary Research, Ss. Cyril and Methodius University, Skopje, North Macedonia\n",
    "</p>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "\n",
    "\n",
    "**Purpose:** T1 mapping is a widely used quantitative MRI technique, but its tissue-specific values remain inconsistent across protocols, sites, and vendors. The ISMRM Reproducible Research study group (RRSG) and Quantitative MR study group (qMRSG) jointly launched a T1 mapping reproducibility challenge to assess the reproducibility of a well-established inversion recovery T1 mapping technique, published solely as a PDF, on a standardized phantom and in healthy human brains.\n",
    "\n",
    "\n",
    "**Methods:** The challenge used the acquisition protocol and fitting algorithm from Barral et al. 2010. Participants collected T1 mapping data on the ISMRM/NIST phantom and/or in healthy human brains. Data submission, pipeline development, and analysis were conducted using open-source platforms. Inter-submission and intra-submission comparisons were performed using one dataset per submission.\n",
    "\n",
    "\n",
    "\n",
    "**Results:** Eighteen submissions were accepted using data collected with three MRI manufacturers, primarily at 3T (with one submission at 0.35T). The study collected 39 phantom and 56 human datasets. The mean coefficient of variation (CoV) was 6.1% for inter-submission phantom measurements, which was nearly twice as high as the intra-submission CoV (2.9%). For human data, inter-/intra-submission CoV was 5.9/3.2 % in the genu of the corpus callosum and 16/6.9 % in the cortical gray matter. To facilitate broader community access and engagement, an interactive dashboard was developed and is available at<a href = \"https://rrsg2020.dashboards.neurolibre.org\">https://rrsg2020.dashboards.neurolibre.org</a>.\n",
    "\n",
    "**Conclusion:** The inter-submission variability was twice as high as the intra-submission variability in both phantom and human brain T1 measurements, indicating that the published PDF was not sufficient to reproduce a quantitative MRI protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"display:inline\"><center> Dashboard: Challenge Submissions </center></h2>\n",
    "<iframe src=\"https://rrsg2020.dashboards.neurolibre.org\" width=\"120%\" height=\"750px\" style=\"border:none;margin: 0 -10%\"></iframe>\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 &nbsp; &nbsp; | &nbsp; &nbsp; INTRODUCTION\n",
    "\n",
    "\n",
    "Significant challenges exist in the reproducibility of quantitative MRI (qMRI) [1]. Despite its promise of improving the specificity and reproducibility of MRI acquisitions, few qMRI techniques have been integrated into clinical practice. Even the most fundamental MR parameters cannot be measured with sufficient reproducibility and precision across clinical scanners to pass the second of six stages of technical assessment for clinical biomarkers [2–4]. Half a century has passed since the first quantitative T1 (spin-lattice relaxation time) measurements were first reported as a potential biomarker for tumors [5], followed shortly thereafter by the first in vivo T1 maps [6] of tumors, but there is still disagreement in reported values for this fundamental parameter across different sites, vendors, and implementations [7].\n",
    "\n",
    "\n",
    "Among fundamental MRI parameters, T1 holds significant importance [8]. T1 represents the time constant for recovery of equilibrium longitudinal magnetization. T1 values will vary depending on the molecular mobility and magnetic field strength [9–11]. Knowledge of the T1 values for tissue is crucial for optimizing clinical MRI sequences for contrast and time efficiency [12–14] and to calibrate other  quantitative MRI techniques [15,16]. Inversion recovery (IR) [17,18] is considered the gold standard for T1 measurement due to its robustness, but its long acquisition times limit the clinical use of IR for T1 mapping [7]. In practice, IR is often used as a reference for validating other T1 mapping techniques, such as variable flip angle imaging (VFA) [19–21], Look-Locker [22–24], and MP2RAGE [25,26].\n",
    "\n",
    "\n",
    "In ongoing efforts to standardize T1 mapping methods, researchers have been actively developing quantitative MRI phantoms [27]. The International Society for Magnetic Resonance in Medicine (ISMRM) and the National Institute of Standards and Technology (NIST) collaborated on a standard system phantom [28], which was subsequently commercialized (Premium System Phantom, CaliberMRI, Boulder, Colorado). This phantom has since been used in large multicenter studies, such as Bane et al. [29] which concluded that acquisition protocol and field strength influence accuracy, repeatability, and interplatform reproducibility. Another NIST-led study [30] found no significant T1 discrepancies among measurements using NIST protocols across 27 MRI systems from three vendors at two clinical field strengths. \n",
    "\n",
    "The 2020 ISMRM reproducibility challenge  posed the following question: can an imaging protocol, independently implemented at multiple centers, consistently measure one of the fundamental MRI parameters (T1)? To assess this, we proposed using inversion recovery on a standardized phantom (ISMRM/NIST system phantom) and the healthy human brain. Specifically, **this challenge explored whether the information provided in a published PDF of a seminal paper on T1 mapping [31] is sufficient to ensure the reproducibility across independent research imaging groups.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 &nbsp; &nbsp; | &nbsp; &nbsp; METHODS\n",
    "\n",
    "## 2.1 &nbsp; &nbsp; | &nbsp; &nbsp; Phantom and human data\n",
    "\n",
    "\n",
    "The challenge asked participants with access to the ISMRM/NIST system phantom [28] (Premium System Phantom, CaliberMRI, Boulder, Colorado) to measure T1 maps of the phantom’s T1 plate (Table 1). Researchers that  participated in the challenge were instructed to record the temperature before and after scanning the phantom using the phantom's internal thermometer. Instructions for positioning and setting up the phantom were devised by NIST and were provided to participants through their website . In brief, the instructions explained how to orient the phantom and how long the phantom should be in the scanner room prior to scanning to achieve thermal equilibrium.\n",
    "\n",
    "\n",
    "```{list-table} Reference  T1 values of the NiCl2 array of the standard system phantom (for both phantom versions) measured at 20 °C and 3T. Phantoms with serial numbers 0042 or less are referred to as “Version 1”, and those 0043 or greater are “Version 2”.\n",
    ":header-rows: 1\n",
    ":name: table1\n",
    "\n",
    "* - Sphere\n",
    "  - Version 1 (ms)\n",
    "  - Version 2 (ms)\n",
    "* - 1  \n",
    "  - 1989 ± 1.0\n",
    "  - 1883.97 ± 30.32\n",
    "* - 2  \n",
    "  - 1454 ± 2.5\n",
    "  - 1330.16 ± 20.41\n",
    "* - 3  \n",
    "  - 984.1 ± 0.33\n",
    "  - 987.27 ± 14.22\n",
    "* - 4  \n",
    "  - 706 ± 1.0\n",
    "  - 690.08 ± 10.12\n",
    "* - 5  \n",
    "  - 496.7 ± 0.41\n",
    "  - 484.97 ± 7.06\n",
    "* - 6  \n",
    "  - 351.5 ± 0.91\n",
    "  - 341.58 ± 4.97\n",
    "* - 7  \n",
    "  - 247.13 ± 0.086\n",
    "  - 240.86 ± 3.51\n",
    "* - 8  \n",
    "  - 175.3 ± 0.11\n",
    "  - 174.95 ± 2.48\n",
    "* - 9  \n",
    "  - 125.9 ± 0.33\n",
    "  - 121.08 ± 1.75\n",
    "* - 10  \n",
    "  - 89.0 ± 0.17\n",
    "  - 85.75 ± 1.24\n",
    "* - 11  \n",
    "  - 62.7 ± 0.13\n",
    "  - 60.21 ± 0.87\n",
    "* - 12  \n",
    "  - 44.53 ± 0.090\n",
    "  - 42.89 ± 0.44\n",
    "* - 13  \n",
    "  - 30.84 ± 0.016\n",
    "  - 30.40 ± 0.62\n",
    "* - 14  \n",
    "  - 21.719 ± 0.005\n",
    "  - 21.44 ± 0.31\n",
    "```\n",
    "\n",
    "Participants were also instructed to collect T1 maps in healthy human brains, and were asked to measure a single slice positioned parallel to the anterior commissure - posterior commissure (AC-PC) line. Prior to imaging, the participants consented  to share their de-identified data with the challenge organizers and on the Open Science Framework (OSF.io) website. As the submitted data was a single slice, the researchers were not instructed to de-face the data of their participants. Researchers submitting human data provided written confirmation to the organizers that their data was acquired in accordance with their institutional ethics committee (or equivalent regulatory body) and that the subjects had consented to data sharing as outlined in the challenge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 &nbsp; &nbsp; | &nbsp; &nbsp; MRI acquisition protocol\n",
    "\n",
    "Participants followed the inversion recovery T1 mapping protocol optimized for the human brain as described in the published PDF [31], which consisted of: TR = 2550 ms, TIs = 50, 400, 1100, 2500 ms, TE = 14 ms, 2 mm slice thickness and 1×1 mm2 in-plane resolution. Note that this protocol is not suitable for fitting models that assume TR > 5T1. Instead, the more general Barral et al. [31] fitting model described in Section 2.4.1 can be used, and this model is compatible with both magnitude-only and complex data. Researchers were instructed to closely adhere to this protocol and report any deviations due to technical limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 &nbsp; &nbsp; | &nbsp; &nbsp; Data Submissions\n",
    "\n",
    "Data submissions for the challenge were handled through a GitHub repository [https://github.com/rrsg2020/data_submission](https://github.com/rrsg2020/data_submission), enabling a standardized and transparent process. All datasets were converted to the NIfTI format, and images for all TIs were concatenated along the fourth dimension. Each submission included a YAML file to store additional information (submitter details, acquisition details, and phantom or human subject details). Submissions were reviewed, and following acceptance the datasets were uploaded to OSF.io ([osf.io/ywc9g/](osf.io/ywc9g/)). A Jupyter Notebook [32,33] pipeline using qMRLab [34,35] was used to process the T1 maps and to conduct quality-control checks. MyBinder links to Jupyter notebooks that reproduced each T1 map were shared in each respective submission GitHub issue to easily reproduce the results in web browsers while maintaining consistent computational environments. Eighteen submissions were included in the analysis, which resulted in 39 T1 maps of the NIST/system phantom, and 56 brain T1 maps. Figure 1 illustrates all the submissions that acquired phantom data (Figure 1-a) and human data (Figure 1-b), the MRI scanner vendors, and the resulting T1 mapping datasets. Some submissions included measurements where both complex and magnitude-only data from the same acquisition were used to fit T1 maps, thus the total number of unique acquisitions is lower than the numbers reported above (27 for phantom data and 44 for human data). The datasets were collected on systems from three MRI manufacturers (Siemens, GE, Philips) and were acquired at 3T , except for one dataset acquired at 0.35T (the ViewRay MRidian MR-linac).\n",
    "\n",
    "```{image} images/figure_1.png\n",
    "---\n",
    "width: 900px\n",
    "name: fig1\n",
    "align: center\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 &nbsp; &nbsp; | &nbsp; &nbsp; Fitting Model and Pipeline\n",
    "\n",
    "A reduced-dimension non-linear least squares (RD-NLS) approach was used to fit the complex general inversion recovery signal equation:\n",
    "\n",
    "```{math}\n",
    ":label: my_label\n",
    "S(TI) = a + be^{-TI/T_1}\n",
    "```\n",
    "\n",
    "where a and b are complex constants. This approach, developed by Barral et al. [31], offers a model for the general T1 signal equation without relying on the long-TR approximation. The a and b constants inherently factor TR in them, as well as other imaging parameters such as excitation and inversion pulse flip angles, TE, etc. Barral et al. [31] shared their MATLAB (MathWorks, Natick, MA) code for the fitting algorithm used in their paper . Magnitude-only data were fitted to a modified version of Eq. 1 (Eq. 15 of Barral et al. 2010) with signal-polarity restoration by finding the signal minima, fitting the inversion recovery curve for two cases (data points for TI < TIminimum flipped, and data points for TI ≤ TIminimum flipped), and selecting the case that resulted in the best fit. This code is available as part of the open-source software qMRLab [34,35], which provides a standardized application program interface (API) to call the fitting in MATLAB/Octave scripts.\n",
    "\n",
    "\n",
    "A data processing pipeline was written using MATLAB/Octave in a Jupyter Notebook. This pipeline downloads every dataset from osf.io (osf.io/ywc9g/), loads their configuration file, fits the T1 maps, and then saves them to NIfTI and PNG formats. The code is available on GitHub (https://github.com/rrsg2020/t1_fitting_pipeline, filename: RRSG_T1_fitting.ipynb). Finally, T1 maps were manually uploaded to OSF (https://osf.io/ywc9g/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 &nbsp; &nbsp; | &nbsp; &nbsp; Image Labeling & Registration\n",
    "\n",
    "The T1 plate (NiCl2 array) of the phantom has 14 spheres that were labeled as the regions-of-interest (ROI) using a numerical mask template created in MATLAB, provided by NIST researchers (Figure 1-c). To avoid potential edge effects in the T1 maps, the ROI labels were reduced to 60% of the expected sphere diameter. A registration pipeline in Python using the Advanced Normalization Tools (ANTs) [36] was developed and shared in the analysis repository of our GitHub organization (https://github.com/rrsg2020/analysis, filename: register_t1maps_nist.py, commit ID: 8d38644). Briefly, a label-based registration was first applied to obtain a coarse alignment, followed by an affine registration (gradientStep: 0.1, metric: cross correlation, number of steps: 3, iterations: 100/100/100, smoothness: 0/0/0, sub-sampling: 4/2/1) and a BSplineSyN registration (gradientStep:0.5, meshSizeAtBaseLevel:3, number of steps: 3, iterations: 50/50/10, smoothness: 0/0/0, sub-sampling: 4/2/1). The ROI labels template was nonlinearly registered to each T1 map uploaded to OSF.\n",
    "\n",
    "\n",
    "For human data, manual ROIs were segmented by a single researcher (M.B., 11+ years of neuroimaging experience) using FSLeyes [37] in four regions (Figure 1-d): located in the genu, splenium, deep gray matter, and cortical gray matter. Automatic segmentation was not used because the data were single-slice and there was inconsistent slice positioning between datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 &nbsp; &nbsp; | &nbsp; &nbsp; Analysis and Statistics\n",
    "\n",
    "Analysis code and scripts were developed and shared in a version-controlled public GitHub repository . The T1 fitting and data analysis were performed by M.B., one of the challenge organizers. Computational environment requirements were containerized in Docker [38,39] to create an executable environment that allows for analysis reproduction in a web browser via MyBinder  [40]. Backend Python files handled reference data, database operations, ROI masking, and general analysis tools. Configuration files handled dataset information, and the datasets were downloaded and pooled using a script (make_pooled_datasets.py). The databases were created using a reproducible Jupyter Notebook script and subsequently saved in the repository.\n",
    "\n",
    "\n",
    "The mean T1 values of the ISMRM/NIST phantom data for each ROI were compared with temperature-corrected reference values and visualized in three different types of plots (linear axes, log-log axes, and error relative to the reference value). Temperature correction involved nonlinear interpolation  of a NIST reference table of T1 values for temperatures ranging from 16 °C to 26 °C (2 °C intervals) as specified in the phantom’s technical specifications. For the human datasets, the mean and standard deviations for each tissue ROI were calculated from all submissions across all sites. All quality assurance and analysis plot images were stored in the repository. Additionally, the database files of ROI values and acquisition details for all submissions were also stored in the repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 &nbsp; &nbsp; | &nbsp; &nbsp; Dashboard\n",
    "\n",
    "To widely disseminate the challenge results, a web-based dashboard was developed (Figure 2, https://rrsg2020.dashboards.neurolibre.org). The landing page (Figure 2-a) showcases the relationship between the phantom and brain datasets acquired at different sites/vendors. Selecting the Phantom or In Vivo icons and then clicking an ROI will display whisker plots for that region. Additional sections of the dashboard allow for displaying statistics summaries for both sets of data, a magnitude vs complex data fitting comparison, and hierarchical shift function analyses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"https://rrsg2020.dashboards.neurolibre.org\" width=\"120%\" height=\"750px\" style=\"border:none;margin: 0 -10%\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"caption\">\n",
    "<b>Figure 2</b> Dashboard. a) Welcome page listing all the sites, the types of subject, and scanner, and the relationship between the three. b) The phantom tab for a selected ROI, and c) The in vivo tab for a selected ROI. Link: https://rrsg2020.dashboards.neurolibre.org\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 &nbsp; &nbsp; | &nbsp; &nbsp; RESULTS\n",
    "\n",
    "Figure 3 presents a comprehensive overview of the challenge results through violin plots, depicting inter- and intra- submission comparisons in both phantoms (a) and human (b) datasets. Inter-submission coefficients of variation (CoV) were computed by selecting a single T1 map submitted by each challenge participant  and calculating the CoV. For the phantom (Figure 3-a), the average inter-submission CoV for the first five spheres, representing the expected T1 value range in the human brain (approximately 500 to 2000 ms) was 6.1 %. By addressing outliers from two sites associated with specific challenges for sphere 4 (signal null near a TI), the mean inter-submission CoV reduced to 4.1%. One participant (submission 6, Figure 1) measured T1 maps using a consistent protocol at 7 different sites, and the mean intra-submission CoV across the first five spheres for this submission was calculated to be 2.9 %.\n",
    "\n",
    "\n",
    "For the human datasets, inter-submission CoVs for independently-implemented imaging protocols were 5.9% for genu, 10.6% for splenium, 16% for cortical GM, and 22% for deep GM. One participant (submission 18, Figure 1) measured a large dataset (13 individuals) on three scanners and two vendors, and the intra-submission CoVs for this submission were 3.2% for genu, 3.1% for splenium, 6.9 % for cortical GM, and 7.1% for deep GM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{image} images/figure_3.png\n",
    "---\n",
    "width: 900px\n",
    "name: fig3\n",
    "align: center\n",
    "---\n",
    "```\n",
    "\n",
    "<p class=\"caption\">\n",
    "<b>Figure 3</b> Summary of results of the challenge as violin plots displaying the inter- and intra- submission dataset comparisons for phantoms (a) and human brains (b). Interactive figure available at: https://preprint.neurolibre.org/10.55458/neurolibre.00014/.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A scatterplot of the T1 data for all submissions and their ROIs is shown in Figure 4 (phantom a-c, and human brains d-f). The NIST T1 data is shown in Figure 4 a-c, and the same ROI T1 values are presented in each plot for different axes types (linear, log, and error) to better visualize the results. Figure 4-a shows good agreement for this dataset in comparison with the temperature-corrected reference T1 values. However, this trend did not persist for low T1 values (T1 < 100-200 ms), as seen in the log-log plot (Figure 4-b), which was expected because the imaging protocol is optimized for human water-based T1 values (T1 > 500 ms). Higher variability is seen at long T1 values (T1 ~ 2000 ms) in Figure 4-a. Errors exceeding 10% are observed in the phantom spheres with T1 values below 300 ms (Figure 4-c), and 3-4 measurements with outlier values exceeding 10% error were observed in the human water-based tissue range (~500-2000 ms).\n",
    "\n",
    "\n",
    "Figure 4 d-f displays the scatter plot data for human datasets submitted to this challenge, showing mean and standard deviation T1 values from the WM (genu and splenium) and GM (cerebral cortex and deep GM) ROIs. Mean WM T1 values across all submissions were 828 ± 38 ms in the genu and 852 ± 49 ms in the splenium, and mean GM T1 values were 1548 ± 156 ms in the cortex and 1188 ± 133 ms in the deep GM, with less variations overall in WM compared to GM, possibly due to better ROI placement and less partial voluming in WM. The lower standard deviations for the ROIs of human database ID site 9 (submission 18, Figure 1) are due to good slice positioning, cutting through the AC-PC line and the genu for proper ROI placement, particularly for the corpus callosum and deep GM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import os\n",
    "\n",
    "if build == 'latest':\n",
    "    if path.isdir('analysis')== False:\n",
    "        !git clone https://github.com/rrsg2020/analysis.git\n",
    "        dir_name = 'analysis'\n",
    "        analysis = os.listdir(dir_name)\n",
    "\n",
    "        for item in analysis:\n",
    "            if item.endswith(\".ipynb\"):\n",
    "                os.remove(os.path.join(dir_name, item))\n",
    "            if item.endswith(\".md\"):\n",
    "                os.remove(os.path.join(dir_name, item))\n",
    "elif build == 'archive':\n",
    "    if os.path.isdir(Path('../../data')):\n",
    "        data_path = ['../../data/rrsg-2020-neurolibre']\n",
    "    else:\n",
    "        # define data requirement path\n",
    "        data_req_path = os.path.join(\"..\", \"binder\", \"data_requirement.json\")\n",
    "        # download data\n",
    "        repo2data = Repo2Data(data_req_path)\n",
    "        data_path = repo2data.install()         \n",
    "\n",
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from analysis.src.database import *\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('analysis/custom_matplotlibrc')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "fig_id = 0\n",
    "\n",
    "# Configurations\n",
    "if build == 'latest':\n",
    "    database_path = Path('analysis/databases/3T_human_T1maps_database.pkl')\n",
    "    output_folder = Path(\"analysis/plots/08_wholedataset_scatter_Human/\")\n",
    "elif build=='archive':\n",
    "    database_path = Path(data_path[0] + '/analysis/databases/3T_human_T1maps_database.pkl')\n",
    "    output_folder = Path(data_path[0] + '/analysis/plots/08_wholedataset_scatter_Human/')\n",
    "\n",
    "estimate_type = 'mean' # median or mean\n",
    "\n",
    "# Define functions\n",
    "\n",
    "def plot_both_scatter(x1, x2, y, y_std,\n",
    "                      title, x1_label, x2_label, y_label,\n",
    "                      file_prefix, folder_path, fig_id):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "    fig, axs = plt.subplots(2)\n",
    "    fig.suptitle(title)\n",
    "    axs[0].errorbar(x1, y, y_std, fmt='o', solid_capstyle='projecting')\n",
    "    axs[0].set_xlabel(x1_label)\n",
    "    axs[0].set_ylabel(y_label)\n",
    "    axs[0].set_xticks(np.arange(0, np.max(x1), step=1))\n",
    "\n",
    "\n",
    "    axs[1].errorbar(x2, y, y_std, fmt='o', solid_capstyle='projecting')\n",
    "    axs[1].set_xlabel(x2_label)\n",
    "    axs[1].set_ylabel(y_label)\n",
    "    axs[1].set_xticklabels(labels=x2, rotation=90)\n",
    "\n",
    "\n",
    "    if fig_id<10:\n",
    "        filename = \"0\" + str(fig_id) + \"_\" + file_prefix\n",
    "    else:\n",
    "        filename = str(fig_id) + \"_\" + file_prefix\n",
    "\n",
    "    fig.savefig(folder_path / (str(filename) + '.svg'), facecolor='white')\n",
    "    fig.savefig(folder_path / (str(filename) + '.png'), facecolor='white')\n",
    "    fig_id = fig_id + 1\n",
    "    plt.show()\n",
    "    return fig_id\n",
    "\n",
    "# Load database\n",
    "\n",
    "df = pd.read_pickle(database_path)\n",
    "\n",
    "genu_estimate = np.array([])\n",
    "genu_std = np.array([])\n",
    "splenium_estimate = np.array([])\n",
    "splenium_std = np.array([])\n",
    "deepgm_estimate = np.array([])\n",
    "deepgm_std = np.array([])\n",
    "cgm_estimate = np.array([])\n",
    "cgm_std = np.array([])\n",
    "\n",
    "ii = 0\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    if estimate_type is 'mean':\n",
    "        genu_estimate = np.append(genu_estimate, np.mean(df.loc[index]['T1 - genu (WM)']))\n",
    "        genu_std = np.append(genu_std, np.std(df.loc[index]['T1 - genu (WM)']))\n",
    "        splenium_estimate = np.append(splenium_estimate, np.mean(df.loc[index]['T1 - splenium (WM)']))\n",
    "        splenium_std = np.append(splenium_std, np.std(df.loc[index]['T1 - splenium (WM)']))\n",
    "        deepgm_estimate = np.append(deepgm_estimate, np.mean(df.loc[index]['T1 - deep GM']))\n",
    "        deepgm_std = np.append(deepgm_std, np.std(df.loc[index]['T1 - deep GM']))\n",
    "        cgm_estimate = np.append(cgm_estimate, np.mean(df.loc[index]['T1 - cortical GM']))\n",
    "        cgm_std = np.append(cgm_std, np.std(df.loc[index]['T1 - cortical GM']))\n",
    "    elif estimate_type is 'median':\n",
    "        genu_estimate = np.append(genu_estimate, np.median(df.loc[index]['T1 - genu (WM)']))\n",
    "        genu_std = np.append(genu_std, np.std(df.loc[index]['T1 - genu (WM)']))\n",
    "        splenium_estimate = np.append(splenium_estimate, np.median(df.loc[index]['T1 - splenium (WM)']))\n",
    "        splenium_std = np.append(splenium_std, np.std(df.loc[index]['T1 - splenium (WM)']))\n",
    "        deepgm_estimate = np.append(deepgm_estimate, np.median(df.loc[index]['T1 - deep GM']))\n",
    "        deepgm_std = np.append(deepgm_std, np.std(df.loc[index]['T1 - deep GM']))\n",
    "        cgm_estimate = np.append(cgm_estimate, np.median(df.loc[index]['T1 - cortical GM']))\n",
    "        cgm_std = np.append(cgm_std, np.std(df.loc[index]['T1 - cortical GM']))\n",
    "    else:\n",
    "        Exception('Unsupported dataset estimate type.')\n",
    "    ii = ii +1\n",
    "\n",
    "# Store the IDs\n",
    "indexes_numbers = df.index\n",
    "indexes_strings = indexes_numbers.map(str)\n",
    "\n",
    "x1_label='Site #'\n",
    "x2_label='Site #.Meas #'\n",
    "y_label=\"T$_1$ (ms)\"\n",
    "file_prefix = 'WM_and_GM'\n",
    "folder_path=output_folder\n",
    "\n",
    "x1=indexes_numbers\n",
    "x2=indexes_strings\n",
    "y=genu_estimate\n",
    "y_std=genu_std\n",
    "\n",
    "# Paper formatting of x tick labels (remove leading zero, pad zero at the end for multiples of 10)\n",
    "x3=[]\n",
    "for num in x2:\n",
    "    x3.append(num.replace('.0', '.'))\n",
    "\n",
    "index=0\n",
    "for num in x3:\n",
    "    if num[-3] != '.':\n",
    "        x3[index]=num+'0'\n",
    "    index+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "report_output",
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'im_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m yAxis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m256\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# T1 maps\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m im_2_padded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(\u001b[43mim_2\u001b[49m,\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     31\u001b[0m images_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((im_1, im_5, im_3), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m images_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((im_4, im_2_padded, im_6), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'im_2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from os import path\n",
    "import os\n",
    "\n",
    "if build == 'latest':\n",
    "    if path.isdir('analysis')== False:\n",
    "        !git clone https://github.com/rrsg2020/analysis.git\n",
    "        dir_name = 'analysis'\n",
    "        analysis = os.listdir(dir_name)\n",
    "\n",
    "        for item in analysis:\n",
    "            if item.endswith(\".ipynb\"):\n",
    "                os.remove(os.path.join(dir_name, item))\n",
    "            if item.endswith(\".md\"):\n",
    "                os.remove(os.path.join(dir_name, item))\n",
    "elif build == 'archive':\n",
    "    if os.path.isdir(Path('../../data')):\n",
    "        data_path = ['../../data/rrsg-2020-neurolibre']\n",
    "    else:\n",
    "        # define data requirement path\n",
    "        data_req_path = os.path.join(\"..\", \"binder\", \"data_requirement.json\")\n",
    "        # download data\n",
    "        repo2data = Repo2Data(data_req_path)\n",
    "        data_path = repo2data.install()\n",
    "\n",
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from analysis.src.database import *\n",
    "from analysis.src.nist import get_reference_NIST_values, get_NIST_ids\n",
    "from analysis.src.tools import calc_error\n",
    "from analysis.src.nist import temperature_correction\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('analysis/custom_matplotlibrc')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "fig_id = 0\n",
    "\n",
    "if build == 'latest':\n",
    "    database_path = Path('analysis/databases/3T_NIST_T1maps_database.pkl')\n",
    "    output_folder = Path(\"analysis/plots/03_singledataset_scatter_NIST-temperature-corrected/\")\n",
    "elif build=='archive':\n",
    "    database_path = Path(data_path[0] + '/analysis/databases/3T_NIST_T1maps_database.pkl')\n",
    "    output_folder = Path(data_path[0] + '/analysis/plots/03_singledataset_scatter_NIST-temperature-corrected/')\n",
    "\n",
    "estimate_type = 'mean' # median or mean\n",
    "\n",
    "## Define Functions\n",
    "def plot_single_scatter(x, y, y_std,\n",
    "                        title, x_label, y_label,\n",
    "                        file_prefix, folder_path, fig_id,\n",
    "                        y_type='linear'):\n",
    "    if y_type is 'linear':\n",
    "        plt.errorbar(x,y, y_std, fmt='o', solid_capstyle='projecting')\n",
    "        ax = plt.gca()\n",
    "        ax.axline((1, 1), slope=1, linestyle='dashed')\n",
    "        ax.set_ylim(ymin=0, ymax=2500)\n",
    "        ax.set_xlim(xmin=0, xmax=2500)\n",
    "    if y_type is 'log':\n",
    "        plt.loglog(x,y,'o')\n",
    "        ax = plt.gca()\n",
    "        ax.set_ylim(ymin=20, ymax=2500)\n",
    "        ax.set_xlim(xmin=20, xmax=2500)\n",
    "    if y_type is 'error_t1':\n",
    "        plt.errorbar(x,calc_error(x,y), fmt='o')\n",
    "        ax = plt.gca()\n",
    "        ax.axline((1, 0), slope=0, color='k')\n",
    "        ax.axline((1, -10), slope=0, linestyle='dashed', color='k')\n",
    "        ax.axline((1, 10), slope=0, linestyle='dashed', color='k')\n",
    "        ax.set_ylim(ymin=-100, ymax=100)\n",
    "        ax.set_xlim(xmin=0, xmax=2500)\n",
    "\n",
    "\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    \n",
    "\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if fig_id<10:\n",
    "        filename = \"0\" + str(fig_id) + \"_\" + file_prefix\n",
    "    else:\n",
    "        filename = str(fig_id) + \"_\" + file_prefix\n",
    "\n",
    "    fig.savefig(folder_path / (str(filename) + '.svg'), facecolor='white')\n",
    "    fig.savefig(folder_path / (str(filename) + '.png'), facecolor='white')\n",
    "    fig_id = fig_id + 1\n",
    "    plt.show()\n",
    "    return fig_id\n",
    "\n",
    "## Load database\n",
    "\n",
    "df = pd.read_pickle(database_path)\n",
    "\n",
    "## Initialize array\n",
    "\n",
    "dataset_estimate = np.array([])\n",
    "dataset_std = np.array([])\n",
    "\n",
    "index = 6.001\n",
    "\n",
    "serial_number = df.loc[index]['phantom serial number']\n",
    "\n",
    "\n",
    "for key in get_NIST_ids():\n",
    "    if estimate_type == 'mean':\n",
    "        dataset_estimate = np.append(dataset_estimate, np.mean(df.loc[index][key]))\n",
    "    elif estimate_type == 'median':\n",
    "        dataset_estimate = np.append(dataset_estimate, np.median(df.loc[index][key]))\n",
    "    else:\n",
    "        Exception('Unsupported dataset estimate type.')\n",
    "\n",
    "    dataset_std = np.append(dataset_std, np.std(df.loc[index][key]))\n",
    "\n",
    "ref_values = get_reference_NIST_values(serial_number)\n",
    "\n",
    "temperature = df.loc[index]['phantom temperature']\n",
    "temp_corrected_ref_values = temperature_correction(temperature, serial_number)\n",
    "\n",
    "\n",
    "# PYTHON CODE\n",
    "# Module imports\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.image import imread\n",
    "import scipy.io\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "from plotly import __version__\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "config={'showLink': False, 'displayModeBar': False}\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import os\n",
    "import markdown\n",
    "import random\n",
    "from scipy.integrate import quad\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "config={'showLink': False, 'displayModeBar': False}\n",
    "\n",
    "lin_line = go.Scatter(\n",
    "    x=np.linspace(0,2500),\n",
    "    y=np.linspace(0,2500),\n",
    "    name=\"slope\",\n",
    "    line_shape='linear',\n",
    "    line={'dash': 'dash','color': 'black'},\n",
    "    visible = True,\n",
    "    showlegend = False\n",
    ")\n",
    "\n",
    "data_lin=go.Scatter(\n",
    "    x=temp_corrected_ref_values,\n",
    "    y=dataset_estimate,\n",
    "    error_y=dict(\n",
    "        type='data', # value of error bar given in data coordinates\n",
    "        array=dataset_std,\n",
    "        visible=True),\n",
    "    name = 'id: '+ str(index),\n",
    "    mode = 'markers',\n",
    "    marker=dict(color='#007ea7'),\n",
    "    visible = True,\n",
    "    showlegend = False,\n",
    "    )\n",
    "\n",
    "data_log=go.Scatter(\n",
    "    x=temp_corrected_ref_values,\n",
    "    y=dataset_estimate,\n",
    "    name = 'id: '+ str(index),\n",
    "    mode = 'markers',\n",
    "    marker=dict(color='#007ea7'),\n",
    "    visible = True,\n",
    "    showlegend = False\n",
    "    )\n",
    "data_error=go.Scatter(\n",
    "    x=temp_corrected_ref_values,\n",
    "    y= calc_error(temp_corrected_ref_values,dataset_estimate),\n",
    "    name = 'id: '+ str(index),\n",
    "    mode = 'markers',\n",
    "    marker=dict(color='#007ea7'),\n",
    "    visible = True,\n",
    "    showlegend = False\n",
    "    )\n",
    "err_solid_line = go.Scatter(\n",
    "    x=np.linspace(0,2500),\n",
    "    y=np.linspace(0,2500)*0,\n",
    "    name=\"0 % error line\",\n",
    "    line_shape='linear',\n",
    "    line={'dash': 'solid','color': 'black'},\n",
    "    visible = True,\n",
    "    showlegend = False\n",
    ")\n",
    "err_p10_line = go.Scatter(\n",
    "    x=np.linspace(0,2500),\n",
    "    y=np.linspace(0,2500)*0+10,\n",
    "    name=\"+10% error\",\n",
    "    line_shape='linear',\n",
    "    line={'dash': 'dash','color': 'black'},\n",
    "    visible = True,\n",
    "    showlegend = False\n",
    ")\n",
    "err_m10_line = go.Scatter(\n",
    "    x=np.linspace(0,2500),\n",
    "    y=np.linspace(0,2500)*0-10,\n",
    "    name=\"-10% error\",\n",
    "    line_shape='linear',\n",
    "    line={'dash': 'dash','color': 'black'},\n",
    "    visible = True,\n",
    "    showlegend = False\n",
    ")\n",
    "\n",
    "data = [lin_line, data_lin, data_log, data_error, err_solid_line, err_p10_line, err_m10_line]\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(rows=2, cols=3, horizontal_spacing = 0.08)\n",
    "\n",
    "fig.add_trace(\n",
    "    lin_line,\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    data_lin,\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    data_log,\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    data_error,\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    err_solid_line,\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    err_p10_line,\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    err_m10_line,\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "output_folder = Path(\"analysis/plots/04_alldatasets_scatter_NIST-temperature-corrected/\")\n",
    "\n",
    "## Initialize array\n",
    "\n",
    "dataset_mean = np.zeros((1,14))\n",
    "dataset_std = np.zeros((1,14))\n",
    "version = np.array([])\n",
    "temperature = np.array([])\n",
    "ref_values = np.zeros((1,14))\n",
    "\n",
    "\n",
    "ii=0\n",
    "for index, row in df.iterrows():\n",
    "    if type(df.loc[index]['T1 - NIST sphere 1']) is np.ndarray:\n",
    "\n",
    "        version = np.append(version,df.loc[index]['phantom serial number'])\n",
    "        temperature = np.append(temperature, df.loc[index]['phantom temperature'])\n",
    "\n",
    "\n",
    "        if version[ii] is None:\n",
    "            version[ii] = 999 # Missing version, only known case is one where we have version > 42 right now.\n",
    "        \n",
    "        if temperature[ii] is None:\n",
    "            temperature[ii] = 20 # Missing temperature, assume it to be 20C (reference temperature).\n",
    "            \n",
    "            \n",
    "        if ii==0:\n",
    "            ref_values = get_reference_NIST_values(version[ii])\n",
    "            temp_corrected_ref_values = temperature_correction(temperature[ii], version[ii])\n",
    "        else:\n",
    "            ref_values = np.vstack((ref_values, get_reference_NIST_values(version[ii])))\n",
    "            temp_corrected_ref_values = np.vstack((temp_corrected_ref_values, temperature_correction(temperature[ii], version[ii])))\n",
    "        \n",
    "        tmp_dataset_estimate = np.array([])\n",
    "        tmp_dataset_std = np.array([])\n",
    "\n",
    "        for key in get_NIST_ids():\n",
    "            if estimate_type is 'mean':\n",
    "                tmp_dataset_estimate = np.append(tmp_dataset_estimate, np.mean(df.loc[index][key]))\n",
    "            elif estimate_type is 'median':\n",
    "                tmp_dataset_estimate = np.append(tmp_dataset_estimate, np.median(df.loc[index][key]))\n",
    "            else:\n",
    "                Exception('Unsupported dataset estimate type.')\n",
    "\n",
    "            tmp_dataset_std = np.append(tmp_dataset_std, np.std(df.loc[index][key]))\n",
    "\n",
    "        if ii==0:\n",
    "            dataset_estimate = tmp_dataset_estimate  \n",
    "            dataset_std = tmp_dataset_std\n",
    "        else:\n",
    "            dataset_estimate = np.vstack((dataset_estimate, tmp_dataset_estimate))\n",
    "            dataset_std = np.vstack((dataset_std, tmp_dataset_std))\n",
    "\n",
    "        ii=ii+1\n",
    "\n",
    "## Setup for plots\n",
    "fig_id = 0\n",
    "dims=ref_values.shape\n",
    "file_prefix = 'alldatasets'\n",
    "\n",
    "fig.add_trace(\n",
    "    lin_line,\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "for ii in range(dims[0]):\n",
    "    data_lin=go.Scatter(\n",
    "        x=temp_corrected_ref_values[ii,:],\n",
    "        y=dataset_estimate[ii,:],\n",
    "        error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=dataset_std[ii,:],\n",
    "            visible=True),\n",
    "        name = 'id: '+ str(df.index[ii]),\n",
    "        mode = 'markers',\n",
    "        visible = True,\n",
    "        showlegend = False,\n",
    "        )\n",
    "\n",
    "    fig.add_trace(\n",
    "        data_lin,\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "\n",
    "for ii in range(dims[0]):\n",
    "    data_log=go.Scatter(\n",
    "        x=temp_corrected_ref_values[ii,:],\n",
    "        y=dataset_estimate[ii,:],\n",
    "        name = 'id: '+ str(df.index[ii]),\n",
    "        mode = 'markers',\n",
    "        visible = True,\n",
    "        showlegend = False\n",
    "        )\n",
    "\n",
    "    fig.add_trace(\n",
    "        data_log,\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "for ii in range(dims[0]):\n",
    "    data_error=go.Scatter(\n",
    "        x=temp_corrected_ref_values[ii,:],\n",
    "        y= calc_error(temp_corrected_ref_values[ii,:],dataset_estimate[ii,:]),\n",
    "        name = 'id: '+ str(df.index[ii]),\n",
    "        mode = 'markers',\n",
    "        visible = True,\n",
    "        showlegend = False\n",
    "        )\n",
    "\n",
    "    fig.add_trace(\n",
    "        data_error,\n",
    "        row=2, col=3\n",
    "    )\n",
    "\n",
    "fig.add_trace(\n",
    "    err_solid_line,\n",
    "    row=2, col=3\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    err_p10_line,\n",
    "    row=2, col=3\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    err_m10_line,\n",
    "    row=2, col=3\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    type=\"linear\",\n",
    "    range=[0,2500],\n",
    "    title='Reference T<sub>1</sub> (ms)',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    tick0 = 0,\n",
    "    dtick = 500,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=1, col=1\n",
    "    )\n",
    "fig.update_yaxes(\n",
    "    type=\"linear\",\n",
    "    range=[0,2500],\n",
    "    title={\n",
    "        'text':'T<sub>1</sub> estimate (ms)',\n",
    "        'standoff':0\n",
    "        },\n",
    "    showgrid=True,\n",
    "    tick0 = 0,\n",
    "    dtick = 500,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=1, col=1\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(\n",
    "    type=\"log\",\n",
    "    range=[np.log10(20),np.log10(2500)],\n",
    "    title='Reference T<sub>1</sub> (ms)',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    minor=dict(ticks=\"inside\", ticklen=6, showgrid=True),\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=1, col=2\n",
    "    )\n",
    "fig.update_yaxes(\n",
    "    type=\"log\",\n",
    "    range=[np.log10(20),np.log10(2500)],\n",
    "    title={\n",
    "        'text':'T<sub>1</sub> estimate (ms)',\n",
    "        'standoff':0\n",
    "        },\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    minor=dict(ticks=\"inside\", ticklen=6, showgrid=True),\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(\n",
    "    type=\"linear\",\n",
    "    range=[0,2500],\n",
    "    title='Reference T<sub>1</sub> (ms)',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    tick0 = 0,\n",
    "    dtick = 500,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=1, col=3)\n",
    "\n",
    "fig.update_yaxes(\n",
    "    type=\"linear\",\n",
    "    range=[-100,100],\n",
    "    title={\n",
    "        'text':'Error (%)',\n",
    "        'standoff':0\n",
    "        },\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    tick0 = -100,\n",
    "    dtick = 25,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=1, col=3\n",
    "    )\n",
    "\n",
    "\n",
    "fig.update_xaxes(\n",
    "    type=\"linear\",\n",
    "    range=[0,2500],\n",
    "    title='Reference T<sub>1</sub> (ms)',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    tick0 = 0,\n",
    "    dtick = 500,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=2, col=1\n",
    "    )\n",
    "fig.update_yaxes(\n",
    "    type=\"linear\",\n",
    "    range=[0,2500],\n",
    "    title={\n",
    "        'text':'T<sub>1</sub> estimate (ms)',\n",
    "        'standoff':0\n",
    "        },\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    tick0 = 0,\n",
    "    dtick = 500,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=2, col=1\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(\n",
    "    type=\"log\",\n",
    "    range=[np.log10(20),np.log10(2500)],\n",
    "    title='Reference T<sub>1</sub> (ms)',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    minor=dict(ticks=\"inside\", ticklen=6, showgrid=True),\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=2, col=2\n",
    "    )\n",
    "fig.update_yaxes(\n",
    "    type=\"log\",\n",
    "    range=[np.log10(20),np.log10(2500)],\n",
    "    title={\n",
    "        'text':'T<sub>1</sub> estimate (ms)',\n",
    "        'standoff':0\n",
    "        },\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    minor=dict(ticks=\"inside\", ticklen=6, showgrid=True),\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=2, col=2)\n",
    "\n",
    "fig.update_xaxes(\n",
    "    type=\"linear\",\n",
    "    range=[0,2500],\n",
    "    title='Reference T<sub>1</sub> (ms)',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    tick0 = 0,\n",
    "    dtick = 500,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=2, col=3)\n",
    "\n",
    "fig.update_yaxes(\n",
    "    type=\"linear\",\n",
    "    range=[-100,100],\n",
    "    title={\n",
    "        'text':'Error (%)',\n",
    "        'standoff':0\n",
    "        },\n",
    "    showgrid=True,\n",
    "    gridcolor='rgb(169,169,169)',\n",
    "    tick0 = -100,\n",
    "    dtick = 25,\n",
    "    linecolor='black',\n",
    "    linewidth=2,\n",
    "    row=2, col=3,\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=30, r=30, t=10, b=30),\n",
    "    paper_bgcolor='rgb(255, 255, 255)',\n",
    "    plot_bgcolor='rgb(255, 255, 255)',\n",
    "    legend_title=\"\",\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=-0.05,\n",
    "            y=0.53,\n",
    "            showarrow=False,\n",
    "            text='<b>a</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=48\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "        ),\n",
    "        dict(\n",
    "            x=0.32,\n",
    "            y=0.53,\n",
    "            showarrow=False,\n",
    "            text='<b>b</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=48\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "        ),\n",
    "        dict(\n",
    "            x=0.7,\n",
    "            y=0.53,\n",
    "            showarrow=False,\n",
    "            text='<b>c</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=48\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "        ),\n",
    "        dict(\n",
    "            x=-0.05,\n",
    "            y=-0.11,\n",
    "            showarrow=False,\n",
    "            text='<b>d</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=48\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "        ),\n",
    "        dict(\n",
    "            x=0.32,\n",
    "            y=-0.11,\n",
    "            showarrow=False,\n",
    "            text='<b>e</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=48\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "        ),\n",
    "        dict(\n",
    "            x=0.7,\n",
    "            y=-0.11,\n",
    "            showarrow=False,\n",
    "            text='<b>f</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=48\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "        ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=600, width=960)\n",
    "\n",
    "#iplot(fig, filename = 'figure3', config = config)\n",
    "plot(fig, filename = 'figure3.html', config = config)\n",
    "display(HTML('figure3.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "report_output",
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "# PYTHON CODE\n",
    "# Module imports\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.image import imread\n",
    "import scipy.io\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "from plotly import __version__\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "config={'showLink': False, 'displayModeBar': False}\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import os\n",
    "import markdown\n",
    "import random\n",
    "from scipy.integrate import quad\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "config={'showLink': False, 'displayModeBar': False}\n",
    "\n",
    "data_wm=go.Scatter(\n",
    "    x=x3,\n",
    "    y=genu_estimate,\n",
    "    error_y=dict(\n",
    "        type='data', # value of error bar given in data coordinates\n",
    "        array=genu_std,\n",
    "        visible=True),\n",
    "    name = 'White matter (one 5x5 ROI, ~genu)',\n",
    "    mode = 'markers',\n",
    "    marker=dict(color='#007ea7'),\n",
    "    visible = True,\n",
    "    showlegend = False\n",
    "\n",
    "    )\n",
    "\n",
    "data_gm=go.Scatter(\n",
    "    x=x3,\n",
    "    y=cgm_estimate,\n",
    "    error_y=dict(\n",
    "        type='data', # value of error bar given in data coordinates\n",
    "        array=cgm_std,\n",
    "        visible=True),\n",
    "    name = 'Grey matter (three 3x3 ROIs, cortex)',\n",
    "    mode = 'markers',\n",
    "    marker=dict(color='#D22B2B'),\n",
    "    visible = True,\n",
    "    showlegend = False\n",
    "    )\n",
    "\n",
    "\n",
    "data = [data_wm, data_gm]\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    width=960,\n",
    "    height=250,\n",
    "    margin=go.layout.Margin(\n",
    "        l=80,\n",
    "        r=40,\n",
    "        b=80,\n",
    "        t=10,\n",
    "    ),\n",
    "    xaxis_title='Site #.Meas #',\n",
    "    yaxis_title='T<sub>1</sub> (ms)',\n",
    "    font=dict(\n",
    "        family='Times New Roman',\n",
    "        size=22\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        autorange=False,\n",
    "        range=[0,57],\n",
    "        showgrid=False,\n",
    "        linecolor='black',\n",
    "        linewidth=2,\n",
    "        tickangle = -90,\n",
    "        tickmode='linear',\n",
    "        tickfont=dict(\n",
    "            family='Times New Roman',\n",
    "            size=12,\n",
    "        ),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        autorange=False,\n",
    "        range=[0, 2999],\n",
    "        showgrid=True,\n",
    "        dtick=500,\n",
    "        gridcolor='rgb(169,169,169)',\n",
    "        linecolor='black',\n",
    "        linewidth=2,\n",
    "        tickfont=dict(\n",
    "            family='Times New Roman',\n",
    "            size=18,\n",
    "        ),\n",
    "    ),\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=-0.1,\n",
    "            y=-0.5,\n",
    "            showarrow=False,\n",
    "            text='<b>b</b>',\n",
    "            font=dict(\n",
    "                family='Times New Roman',\n",
    "                size=64\n",
    "            ),\n",
    "            xref='paper',\n",
    "            yref='paper'\n",
    "        ),\n",
    "    ],\n",
    "    paper_bgcolor='rgb(255, 255, 255)',\n",
    "    plot_bgcolor='rgb(255, 255, 255)',\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "#iplot(fig, filename = 'figure6b', config = config)\n",
    "plot(fig, filename = 'figure6b.html', config = config)\n",
    "display(HTML('figure6b.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"caption\">\n",
    "<b>Figure 4</b> Measured mean T1 values vs. temperature-corrected NIST reference values of the phantom spheres are presented as linear plots (a), log-log plots (b), and plots of the error relative to reference T1 value (c). The dashed lines in plots (c) represent a ±10 % error. Mean T1 values in two sets of ROIs, white matter (one 5⨯5 voxel ROI, genu) and gray matter (three 3⨯3 voxel ROIs, cortex). Top figure shows all datasets collapsed into sites, whereas the bottom shows each individual dataset. In subplot g), the missing datapoint for deep GM in 10.001 was due to the slice positioning of the acquisition not containing deep GM. Interactive figure available at: https://preprint.neurolibre.org/10.55458/neurolibre.00014/.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 &nbsp; &nbsp; | &nbsp; &nbsp; DISCUSSION\n",
    "\n",
    "The challenge focused on exploring if different research groups could reproduce T1 maps based on the protocol information reported in a published PDF [31]. Eighteen submissions independently implemented the inversion recovery T1 mapping acquisition protocol as outlined in Barral et al. [31], and reported T1 mapping data in a standard quantitative MRI phantom and/or human brains at 27 MRI sites, using systems from three different vendors (GE, Philips, Siemens). The collaborative effort produced an open-source database of 94 T1 mapping datasets, including 38 ISMRM/NIST phantom and 56 human brain datasets. The inter-submission variability was twice as high as the intra-submission variability in both phantom and human brain T1 measurements, **demonstrating that a PDF is not enough for reproducibility in quantitative MRI.**\n",
    "\n",
    "More information is needed to unify all the aspects of a pulse sequence across sites. However, in a vendor-native setting, this is a major challenge given the disparities between proprietary development libraries [41]. Vendor-neutral pulse sequence design platforms [42–44] have emerged as a powerful solution to standardize sequence components at the implementation level. Vendor neutrality has been shown to significantly reduce the variability of T1 maps acquired using VFA across vendors [44]. In the absence of a vendor-neutral framework, a vendor-native alternative is the implementation of a strategy to control the saturation of MT across TRs [45]. Nevertheless, this approach can still benefit from a vendor-neutral approach to enhance accessibility and unify implementations. This is because vendor-specific constraints are recognized to impose limitations on the adaptability of sequences, resulting in significant variability even when implementations are closely aligned within their respective vendor-native development environments [46].\n",
    "\n",
    "The 2020 Reproducibility Challenge, jointly organized by the Reproducible Research and Quantitative MR ISMRM study groups, led to the creation of a large open database of standard quantitative MR phantom and human brain inversion recovery T1 maps. These maps were measured using independently implemented imaging protocols on MRI scanners from three different manufacturers. All collected data, processing pipeline code, computational environment files, and analysis scripts were shared with the goal of promoting reproducible research practices, and an interactive dashboard was developed to broaden the accessibility and engagement of the resulting datasets (https://rrsg2020.dashboards.neurolibre.org). The differences in stability between independently implemented (inter-submission) and centrally shared (intra-submission) protocols observed both in phantoms and in vivo could help inform future meta-analyses of quantitative MRI metrics [47,48] and better guide multi-center collaborations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACKNOWLEDGEMENT\n",
    "\n",
    "<p style=\"text-align:justify;\">\n",
    "The conception of this collaborative reproducibility challenge originated from discussions with experts, including Paul Tofts, Joëlle Barral, and Ilana Leppert, who provided valuable insights. Additionally, Kathryn Keenan, Zydrunas Gimbutas, and Andrew Dienstfrey from NIST provided their code to generate the ROI template for the ISMRM/NIST phantom. Dylan Roskams-Edris and Gabriel Pelletier from the Tanenbaum Open Science Institute (TOSI) offered valuable insights and guidance related to data ethics and data sharing in the context of this international multi-center conference challenge. The 2020 RRSG study group committee members who launched the challenge, Martin Uecker, Florian Knoll, Nikola Stikov, Maria Eugenia Caligiuri, and Daniel Gallichan, as well as the 2020 qMRSG committee members, Kathryn Keenan, Diego Hernando, Xavier Golay, Annie Yuxin Zhang, and Jeff Gunter, also played an essential role in making this challenge possible. We’d also like to extend our thanks to all the volunteers and individuals who helped with the scanning at each imaging site.\n",
    "The authors thank the ISMRM Reproducible Research Study Group for conducting a code review of the code (Version 1) supplied in the Data Availability Statement. The scope of the code review covered only the code’s ease of download, quality of documentation, and ability to run, but did not consider scientific accuracy or code efficiency.\n",
    "\n",
    "\n",
    "Lastly, we acknowledge use of ChatGPT (v3), a generative language model, for accelerating manuscript preparation. The co-first authors employed ChatGPT in the initial draft for transforming bullet point sentences into paragraphs, proofreading for typos, and refining the academic tone. ChatGPT served exclusively as a writing aid, and was not used to create or interpret results.\n",
    "\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AVAILABILITY STATEMENT\n",
    "\n",
    "An interactive NeuroLibre preprint of this manuscript is available at https://preprint.neurolibre.org/10.55458/neurolibre.00014/. All imaging data submitted to the challenge, dataset details, registered ROI maps, and processed T1 maps are hosted on OSF https://osf.io/ywc9g/. The dataset submissions and quality assurance were handled through GitHub issues in this repository https://github.com/rrsg2020/data_submission (commit: 9d7eff1). Note that accepted submissions are closed issues, and that the GitHub branches associated with the issue numbers contain the Dockerfile and Jupyter Notebook scripts that reproduce these preliminary quality assurance results and can be run in a browser using MyBinder. The ROI registration scripts for the phantoms and T1 fitting pipeline to process all datasets are hosted in this GitHub repository, https://github.com/rrsg2020/t1_fitting_pipeline (commit: 3497a4e). All the analyses of the datasets were done using Jupyter Notebooks and are available in this repository, https://github.com/rrsg2020/analysis (commit: 8d38644), which also contains a Dockerfile to reproduce the environment using a tool like MyBinder. A dashboard was developed to explore the datasets information and results in a browser, which is accessible here, https://rrsg2020.dashboards.neurolibre.org, and the code is also available on GitHub: https://github.com/rrsg2020/rrsg2020-dashboard (commit: 6ee9321). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[^rrsg2020-challenge]: [ISMRM blog post announcingn the RRRSG challenge](https://blog.ismrm.org/2019/12/12/reproducibility-challenge-2020-join-the-reproducible-research-and-quantitative-mr-study-groups-in-their-efforts-to-standardize-t1-mapping)\n",
    "\n",
    "[^nist-website]: The [website]( https://collaborate.nist.gov/mriphantoms/bin/view/MriPhantoms/SimpleImagingInstructions) provided to the participants has since been removed from the NIST website.\n",
    "\n",
    "[^phantom-reference]: [Manufacturer's reference for the phantom](https://qmri.com/cmri-product-resources/#premium-system-resources)\n",
    "\n",
    "[^informed-consent]: This [website](https://www.uu.nl/en/research/research-data-management/guides/informed-consent-for-data-sharing) was provided as a resource to the participants for best practices to obtain informed consent for data sharing.\n",
    "\n",
    "[^issue-five]: [rrsg2020/data_submission issue #5](https://github.com/rrsg2020/data_submission/issues/5)\n",
    "\n",
    "[^their-paper]: [http://www-mrsrl.stanford.edu/~jbarral/t1map.html](http://www-mrsrl.stanford.edu/~jbarral/t1map.html)\n",
    "\n",
    "[^public-repo]: [https://github.com/rrsg2020/analysis](https://github.com/rrsg2020/analysis)\n",
    "\n",
    "[^my-binder]: https://mybinder.org/v2/gh/rrsg2020/analysis/master?filepath=analysis\n",
    "\n",
    "[^nonlinear]: The T<sub>1</sub> values vs temperature tables reported by the phantom manufacturer did not always exhibit a linear relationship. We explored the use of spline fitting on the original data and quadratic fitting on the log-log representation of the data, Both methods yielded good results, and we opted to use the latter in our analyses. The code is found [here](https://github.com/rrsg2020/analysis/blob/master/src/nist.py), and a Jupyter Notebook used in temperature interpolation development is [here](https://github.com/rrsg2020/analysis/blob/master/temperature_correction.ipynb).\n",
    "\n",
    "[^dashboard]: Interactive dashboard: [https://rrsg2020.db.neurolibre.org](https://rrsg2020.db.neurolibre.org), code repository: [https://github.com/rrsg2020/rrsg2020-dashboard](https://github.com/rrsg2020/rrsg2020-dashboard)\n",
    "\n",
    "[^hsf]: The hierarchical shift function compares distributions throughout their range across multiple dependent measurements. More information can be found in this article, {cite:p}`Wilcox2023-jf`, and in [this blog post](https://garstats.wordpress.com/2019/02/21/hsf). \n",
    "\n",
    "[^three-t]: Strictly speaking, not all manufacturers operate a 3.0 T. Even though this is the field strength advertised by the system manufacturers, there is some deviation in actual field strength between vendors. The actual center frequencies are typically reported in the DICOM files, and these were shared for most datasets and are available in our OSF.io repository (https://osf.io/ywc9g/). From these datasets, the center frequencies imply participants that used GE and Philips scanners were at 3.0T (`~`127.7 MHz), whereas participants that used Siemens scanners were at 2.89T (`~`123.2 MHz). For simplicity, we will always refer to the field strength in this article as 3T.\n",
    "\n",
    "[^inter-cov]: Only T<sub>1</sub> maps measured using phantom version 1 were included in this inter-submission COV, as including both sets would have increased the COV due to the differences in reference T<sub>1</sub> values. There were seven participants that used version 1, and six that used version 2.\n",
    "\n",
    "[^magnitude-fit]: Due to the noise-floor or artifacts.\n",
    "\n",
    "[^hsf-tab]: See online dashboard https://rrsg2020.dashboards.neurolibre.org/apps/stats and click on the “HSF” tab to view these graphs for all 14 spheres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "\n",
    "\n",
    "1. \tKeenan KE, Biller JR, Delfino JG, Boss MA, Does MD, Evelhoch JL, et al. Recommendations towards standards for quantitative MRI (qMRI) and outstanding needs. J Magn Reson Imaging. 2019;49: e26–e39.\n",
    "2. \tFryback DG, Thornbury JR. The efficacy of diagnostic imaging. Med Decis Making. 1991;11: 88–94.\n",
    "3. \tSchweitzer M. Stages of technical efficacy: Journal of Magnetic Resonance Imaging style. J Magn Reson Imaging. 2016;44: 781–782.\n",
    "4. \tSeiberlich N, Gulani V, Campbell A, Sourbron S, Doneva MI, Calamante F, et al. Quantitative Magnetic Resonance Imaging. Academic Press; 2020.\n",
    "5. \tDamadian R. Tumor detection by nuclear magnetic resonance. Science. 1971;171: 1151–1153.\n",
    "6. \tPykett IL, Mansfield P. A line scan image study of a tumorous rat leg by NMR. Phys Med Biol. 1978;23: 961–967.\n",
    "7. \tStikov N, Boudreau M, Levesque IR, Tardif CL, Barral JK, Pike GB. On the accuracy of T1 mapping: Searching for common ground. Magn Reson Med. 2015;73: 514–522.\n",
    "8. \tBoudreau M, Keenan KE, Stikov N. Quantitative T1 and T1r Mapping. Quantitative Magnetic Resonance Imaging. 2020. pp. 19–45.\n",
    "9. \tBottomley PA, Foster TH, Argersinger RE, Pfeifer LM. A review of normal tissue hydrogen NMR relaxation times and relaxation mechanisms from 1-100 MHz: dependence on tissue type, NMR frequency, temperature, species, excision, and age. Med Phys. 1984;11: 425–448.\n",
    "10. \tWansapura JP, Holland SK, Dunn RS, Ball WS Jr. NMR relaxation times in the human brain at 3.0 tesla. J Magn Reson Imaging. 1999;9: 531–538.\n",
    "11. \tDieringer MA, Deimling M, Santoro D, Wuerfel J, Madai VI, Sobesky J, et al. Rapid parametric mapping of the longitudinal relaxation time T1 using two-dimensional variable flip angle magnetic resonance imaging at 1.5 Tesla, 3 Tesla, and 7 Tesla. PLoS One. 2014;9: e91318.\n",
    "12. \tErnst RR, Anderson WA. Application of Fourier Transform Spectroscopy to Magnetic Resonance. Rev Sci Instrum. 1966;37: 93–102.\n",
    "13. \tRedpath TW, Smith FW. Technical note: use of a double inversion recovery pulse sequence to image selectively grey or white brain matter. Br J Radiol. 1994;67: 1258–1263.\n",
    "14. \tTofts PS. Modeling tracer kinetics in dynamic Gd-DTPA MR imaging. J Magn Reson Imaging. 1997;7: 91–101.\n",
    "15. \tSled JG, Pike GB. Quantitative imaging of magnetization transfer exchange and relaxation properties in vivo using MRI. Magn Reson Med. 2001;46: 923–931.\n",
    "16. \tYuan J, Chow SKK, Yeung DKW, Ahuja AT, King AD. Quantitative evaluation of dual-flip-angle T1 mapping on DCE-MRI kinetic parameter estimation in head and neck. Quant Imaging Med Surg. 2012;2: 245–253.\n",
    "17. \tDrain LE. A Direct Method of Measuring Nuclear Spin-Lattice Relaxation Times. Proc Phys Soc A. 1949;62: 301.\n",
    "18. \tHahn EL. An Accurate Nuclear Magnetic Resonance Method for Measuring Spin-Lattice Relaxation Times. Physical Review. 1949. pp. 145–146. doi:10.1103/physrev.76.145\n",
    "19. \tFram EK, Herfkens RJ, Johnson GA, Glover GH, Karis JP, Shimakawa A, et al. Rapid calculation of T1 using variable flip angle gradient refocused imaging. Magn Reson Imaging. 1987;5: 201–208.\n",
    "20. \tDeoni SCL, Rutt BK, Peters TM. Rapid combinedT1 andT2 mapping using gradient recalled acquisition in the steady state. Magnetic Resonance in Medicine. 2003. pp. 515–526. doi:10.1002/mrm.10407\n",
    "21. \tCheng H-LM, Wright GA. Rapid high-resolutionT1 mapping by variable flip angles: Accurate and precise measurements in the presence of radiofrequency field inhomogeneity. Magnetic Resonance in Medicine. 2006. pp. 566–574. doi:10.1002/mrm.20791\n",
    "22. \tLook DC, Locker DR. Time saving in measurement of NMR and EPR relaxation times. Rev Sci Instrum. 1970;41: 250–251.\n",
    "23. \tMessroghli DR, Radjenovic A, Kozerke S, Higgins DM, Sivananthan MU, Ridgway JP. Modified Look-Locker inversion recovery (MOLLI) for high-resolution T1 mapping of the heart. Magn Reson Med. 2004;52: 141–146.\n",
    "24. \tPiechnik SK, Ferreira VM, Dall’Armellina E, Cochlin LE, Greiser A, Neubauer S, et al. Shortened Modified Look-Locker Inversion recovery (ShMOLLI) for clinical myocardial T1-mapping at 1.5 and 3 T within a 9 heartbeat breathhold. J Cardiovasc Magn Reson. 2010;12: 69.\n",
    "25. \tMarques JP, Kober T, Krueger G, van der Zwaag W, Van de Moortele P-F, Gruetter R. MP2RAGE, a self bias-field corrected sequence for improved segmentation and T1-mapping at high field. NeuroImage. 2010. pp. 1271–1281. doi:10.1016/j.neuroimage.2009.10.002\n",
    "26. \tMarques JP, Gruetter R. New developments and applications of the MP2RAGE sequence--focusing the contrast and high spatial resolution R1 mapping. PLoS One. 2013;8: e69294.\n",
    "27. \tKeenan KE, Ainslie M, Barker AJ, Boss MA, Cecil KM, Charles C, et al. Quantitative magnetic resonance imaging phantoms: A review and the need for a system phantom. Magn Reson Med. 2018;79: 48–61.\n",
    "28. \tStupic KF, Ainslie M, Boss MA, Charles C, Dienstfrey AM, Evelhoch JL, et al. A standard system phantom for magnetic resonance imaging. Magn Reson Med. 2021;86: 1194–1211.\n",
    "29. \tBane O, Hectors SJ, Wagner M, Arlinghaus LL, Aryal MP, Cao Y, et al. Accuracy, repeatability, and interplatform reproducibility of T1 quantification methods used for DCE-MRI: Results from a multicenter phantom study. Magn Reson Med. 2018;79: 2564–2575.\n",
    "30. \tKeenan KE, Gimbutas Z, Dienstfrey A, Stupic KF, Boss MA, Russek SE, et al. Multi-site, multi-platform comparison of MRI T1 measurement using the system phantom. PLoS One. 2021;16: e0252966.\n",
    "31. \tBarral JK, Gudmundson E, Stikov N, Etezadi-Amoli M, Stoica P, Nishimura DG. A robust methodology for in vivo T1 mapping. Magn Reson Med. 2010;64: 1057–1067.\n",
    "32. \tKluyver T, Ragan-Kelley B, Granger B, Bussonnier M, Frederic J, Kelley K, et al. Jupyter Notebooks – a publishing format for reproducible computational workflows. Positioning and Power in Academic Publishing: Players, Agents and Agendas. Amsterdam, NY: IOS Press; 2016. pp. 87–90.\n",
    "33. \tBeg, Taka, Kluyver, Konovalov, Ragan-Kelley, Thiery, et al. Using Jupyter for Reproducible Scientific Workflows. https://www.computer.org › csdl › magazine › 2021/02https://www.computer.org › csdl › magazine › 2021/02. 2021;23: 36–46.\n",
    "34. \tKarakuzu A, Boudreau M, Duval T, Boshkovski T, Leppert I, Cabana J-F, et al. qMRLab: Quantitative MRI analysis, under one umbrella. J Open Source Softw. 2020;5: 2343.\n",
    "35. \tCabana J-F, Gu Y, Boudreau M, Levesque IR, Atchia Y, Sled JG, et al. Quantitative magnetization transfer imagingmadeeasy with qMTLab: Software for data simulation, analysis, and visualization. Concepts Magn Reson Part A Bridg Educ Res. 2015;44A: 263–277.\n",
    "36. \tAvants BB, Tustison N, Song G. Advanced normalization tools (ANTS). Insight J. 2009;2: 1–35.\n",
    "37. \tMcCarthy P. FSLeyes. 2019. doi:10.5281/zenodo.3403671\n",
    "38. \tMerkel D. Docker: Lightweight Linux containers for consistent development and deployment. 2014 [cited 14 Feb 2023]. Available: https://www.seltzer.com/margo/teaching/CS508.19/papers/merkel14.pdf\n",
    "39. \tBoettiger C. An introduction to Docker for reproducible research. Oper Syst Rev. 2015;49: 71–79.\n",
    "40. \tProject Jupyter, Bussonnier M, Forde J, Freeman J, Granger B, Head T, et al. Binder 2.0 - Reproducible, interactive, sharable environments for science at scale. Proceedings of the Python in Science Conference. SciPy; 2018. doi:10.25080/majora-4af1f417-011\n",
    "41. \tGracien, Maiworm, Brüche, Shrestha. How stable is quantitative MRI?–Assessment of intra-and inter-scanner-model reproducibility using identical acquisition sequences and data analysis …. Neuroimage. 2020. Available: https://www.sciencedirect.com/science/article/pii/S1053811919309553\n",
    "42. \tLayton KJ, Kroboth S, Jia F, Littin S, Yu H, Leupold J, et al. Pulseq: A rapid and hardware-independent pulse sequence prototyping framework. Magn Reson Med. 2017;77: 1544–1552.\n",
    "43. \tCordes C, Konstandin S, Porter D, Günther M. Portable and platform-independent MR pulse sequence programs. Magn Reson Med. 2020;83: 1277–1290.\n",
    "44. \tKarakuzu A, Biswas L, Cohen-Adad J, Stikov N. Vendor-neutral sequences and fully transparent workflows improve inter-vendor reproducibility of quantitative MRI. Magn Reson Med. 2022;88: 1212–1228.\n",
    "45. \tA G Teixeira RP, Neji R, Wood TC, Baburamani AA, Malik SJ, Hajnal JV. Controlled saturation magnetization transfer for reproducible multivendor variable flip angle T1 and T2 mapping. Magn Reson Med. 2020;84: 221–236.\n",
    "46. \tLee Y, Callaghan MF, Acosta-Cabronero J, Lutti A, Nagy Z. Establishing intra- and inter-vendor reproducibility of T1 relaxation time measurements with 3T MRI. Magn Reson Med. 2019;81: 454–465.\n",
    "47. \tMancini M, Karakuzu A, Cohen-Adad J, Cercignani M, Nichols TE, Stikov N. An interactive meta-analysis of MRI biomarkers of myelin. Elife. 2020;9. doi:10.7554/eLife.61523\n",
    "48. \tLazari A, Lipp I. Can MRI measure myelin? Systematic review, qualitative assessment, and meta-analysis of studies validating microstructural imaging with myelin histology. Neuroimage. 2021;230: 117744."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
